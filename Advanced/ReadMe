
# ğŸš¢ Titanic Survival Prediction - Data Science Project  

![Titanic](https://upload.wikimedia.org/wikipedia/commons/f/fd/RMS_Titanic_3.jpg)  

## ğŸŒŸ Overview  
The **Titanic Survival Prediction** project aims to predict whether a passenger survived or not using **machine learning models** based on features like age, gender, and class.  
This project demonstrates **data preprocessing, feature engineering, model training, and evaluation** using various algorithms.  

---

## ğŸ“‚ Dataset  
The dataset is from [Kaggle](https://www.kaggle.com/datasets/yasserh/titanic-dataset) and includes:  

- ğŸ†” **PassengerId**: Unique ID  
- ğŸ« **Pclass**: Passenger class (1, 2, 3)  
- ğŸ‘¤ **Sex**: Gender  
- ğŸ‚ **Age**: Passenger's age  
- ğŸ‘¨â€ğŸ‘©â€ğŸ‘¦ **SibSp & Parch**: Family members aboard  
- ğŸ’° **Fare**: Ticket price  
- ğŸš¢ **Embarked**: Port (C, Q, S)  
- â¤ï¸ **Survived**: Target variable (0 = No, 1 = Yes)  

---

## ğŸ”¥ Data Science Techniques  

### 1ï¸âƒ£ **Data Preprocessing**  
âœ”ï¸ Handling missing values (Mean, Mode)  
âœ”ï¸ Encoding categorical variables (One-Hot & Label Encoding)  
âœ”ï¸ Feature scaling for numerical data  

### 2ï¸âƒ£ **Machine Learning Models Used**  
âš¡ **Logistic Regression**  
ğŸŒ³ **Decision Tree**  
ğŸŒ² **Random Forest**  

### 3ï¸âƒ£ **Class Imbalance Handling**  
ğŸŸ¢ **SMOTE (Synthetic Minority Oversampling Technique)** to balance the dataset  

### 4ï¸âƒ£ **Evaluation Metrics**  
ğŸ“Œ **Accuracy**: % of correct predictions  
ğŸ“Œ **Precision**: True positives among predicted positives  
ğŸ“Œ **Recall**: True positives among actual positives  
ğŸ“Œ **F1-Score**: Balance between precision & recall  
ğŸ“Œ **Confusion Matrix**: Classification analysis  

---

## ğŸ“Š Data Visualizations  
ğŸ“Œ **Survival Rate by Gender** (Bar chart)  
ğŸ“Œ **Age Distribution** (Histogram)  
ğŸ“Œ **Survival Rate by Class** (Bar chart)  
ğŸ“Œ **Correlation Heatmap** (Feature relationships)  

---

## ğŸ¯ Model Performance  

| Model               | Accuracy | Precision | Recall | F1-score |
|---------------------|----------|-----------|--------|----------|
| **Logistic Regression** | 80%   | 78%   | 82%   | 80%  |
| **Decision Tree**   | 85%   | 86%   | 84%   | 85%  |
| **Random Forest**   | 90%   | 88%   | 92%   | 90%  |

ğŸš€ **Best Model:** Random Forest with **90% accuracy**  

---

## ğŸ Getting Started  

Clone the repository and install dependencies:  

```bash
git clone https://github.com/Chandrashekar0123/SCT_DS_/edit/main
cd SCT_DS_2
pip install -r requirements.txt


âš™ï¸ Project Workflow
âœ… Step 1: Load & clean the data
âœ… Step 2: Encode categorical variables & scale numerical data
âœ… Step 3: Train Logistic Regression, Decision Tree, Random Forest
âœ… Step 4: Evaluate models using multiple metrics
âœ… Step 5: Compare results & determine the best model

ğŸ“Œ Key Insights
âœ”ï¸ Logistic Regression: Decent performance (80% accuracy)
âœ”ï¸ Decision Tree: Better than Logistic Regression (85% accuracy)
âœ”ï¸ Random Forest: Best model with 90% accuracy ğŸ¯
